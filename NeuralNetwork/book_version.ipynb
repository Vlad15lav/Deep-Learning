{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNNEodaL8YR1W7vDr1JOWM1"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"_uKQLHkssJnR","executionInfo":{"status":"ok","timestamp":1608196947930,"user_tz":-180,"elapsed":655,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pickle"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qQdsCilzshb4"},"source":["# Tools"]},{"cell_type":"code","metadata":{"id":"qO9hALEwsQCt","executionInfo":{"status":"ok","timestamp":1608196948407,"user_tz":-180,"elapsed":619,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["def unpickle(file):\r\n","    with open(file, 'rb') as fo:\r\n","        dict = pickle.load(fo, encoding='bytes')\r\n","    return dict\r\n","\r\n","def getLoader(path, samples, batch_size, shuff=False):\r\n","    load = []\r\n","    for f in samples:\r\n","        data = unpickle(path + f)\r\n","        x_set = data[b'data']\r\n","        t_set = np.array(data[b'labels'])\r\n","\r\n","        # Shuffle\r\n","        if shuff:\r\n","            index = np.arange(x_set.shape[0])\r\n","            np.random.shuffle(index)\r\n","            x_set = x_set[index]\r\n","            t_set = t_set[index]\r\n","\r\n","        x_set = x_set.reshape(x_set.shape[0], 3, 32, 32)\r\n","        x_set = x_set.transpose(0, 2, 3, 1).astype('uint8')\r\n","\r\n","        for i in range(x_set.shape[0] // batch_size):\r\n","            load.append({'imgs': x_set[batch_size * i:batch_size * (i + 1)],\r\n","                         'targets': t_set[batch_size * i:batch_size * (i + 1)]})\r\n","    return load"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"URVYjmSiskmu"},"source":["# Layers"]},{"cell_type":"code","metadata":{"id":"skBiKNKusQaX","executionInfo":{"status":"ok","timestamp":1608196948828,"user_tz":-180,"elapsed":524,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class Param:\r\n","    def __init__(self, value):\r\n","        self.value = value\r\n","        self.grad = np.zeros_like(value)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"m2sMiLEgsQcf","executionInfo":{"status":"ok","timestamp":1608196949527,"user_tz":-180,"elapsed":1170,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class ReLU:\r\n","    def __init__(self):\r\n","        self.deriv = None\r\n","    \r\n","    def __str__(self):\r\n","         return \"ReLU()\"\r\n","    \r\n","    def params(self):\r\n","        return {}\r\n","    \r\n","    def zero_grad(self):\r\n","        pass\r\n","    \r\n","    def forward(self, X, training):\r\n","        self.deriv = (X > 0)\r\n","        return X * self.deriv\r\n","    \r\n","    def backward(self, d_out):\r\n","        d_result = d_out * self.deriv\r\n","        return d_result\r\n","\r\n","class Sigmoid:\r\n","    def __init__(self):\r\n","        self.deriv = None\r\n","    \r\n","    def __str__(self):\r\n","         return \"Sigmoid()\"\r\n","\r\n","    def params(self):\r\n","        return {}\r\n","    \r\n","    def zero_grad(self):\r\n","        pass\r\n","    \r\n","    def forward(self, X, training):\r\n","        self.deriv = (1 / (1 + np.exp(-X))) * (1 - 1 / (1 + np.exp(-X)))\r\n","        return 1 / (1 + np.exp(-X))\r\n","    \r\n","    def backward(self, d_out):\r\n","        d_result = d_out * self.deriv\r\n","        return d_result\r\n","\r\n","class Softmax:\r\n","    def __init__(self):\r\n","        self.deriv = None\r\n","    \r\n","    def __str__(self):\r\n","         return \"Softmax()\"\r\n","\r\n","    def params(self):\r\n","        return {}\r\n","    \r\n","    def zero_grad(self):\r\n","        pass\r\n","    \r\n","    def forward(self, Z_last, training):\r\n","        Z_last -= np.max(Z_last, axis=1).T.reshape((Z_last.shape[0], 1))\r\n","        return np.exp(Z_last) / np.sum(np.exp(Z_last), axis=1).T.reshape((Z_last.shape[0], 1))\r\n","    \r\n","    def backward(self, d_out):\r\n","        return d_out"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6tcYyGqxgKTk"},"source":["# Fully-Connected"]},{"cell_type":"code","metadata":{"id":"05ftJla5gKmb","executionInfo":{"status":"ok","timestamp":1608196949528,"user_tz":-180,"elapsed":761,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class FullyConnected:\r\n","    def __init__(self, n_input, n_output):\r\n","        self.n_size = (n_input, n_output)\r\n","        self.W = Param(np.random.randn(n_output, n_input) * 0.1)\r\n","        self.B = Param(np.random.randn(1, n_output) * 0.1)\r\n","\r\n","        self.Z_before = None\r\n","    \r\n","    def __str__(self):\r\n","         return \"FullyConnected(n_input={}, n_output={})\".format(*self.n_size)\r\n","    \r\n","    def params(self):\r\n","        return {'weight': self.W.value, 'bias': self.B.value}\r\n","    \r\n","    def zero_grad(self):\r\n","        self.W.grad = np.zeros_like(self.W.value)\r\n","        self.B.grad = np.zeros_like(self.B.value)\r\n","\r\n","    def forward(self, X, training):\r\n","        self.Z_before = X.copy()\r\n","        return X @ self.W.value.T + self.B.value\r\n","    \r\n","    def backward(self, d_out):\r\n","        n = self.Z_before.shape[0]\r\n","        self.W.grad += (d_out.T @ self.Z_before) / n\r\n","        self.B.grad += np.sum(d_out, axis=0, keepdims=True) / n\r\n","        return d_out @ self.W.value"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V73NqowIs0fu"},"source":["# CNN"]},{"cell_type":"markdown","metadata":{"id":"PTN9prCqwGys"},"source":["https://github.com/SkalskiP/ILearnDeepLearning.py/blob/ba0b5ba589d4e656141995e8d1a06d44db6ce58d/01_mysteries_of_neural_networks/06_numpy_convolutional_neural_net/src/layers/convolutional.py#L187"]},{"cell_type":"markdown","metadata":{"id":"FKucOh4ig0fn"},"source":["## Tools"]},{"cell_type":"code","metadata":{"id":"Cj88Hc_qFD9g","executionInfo":{"status":"ok","timestamp":1608196950541,"user_tz":-180,"elapsed":1070,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["def get_im2col_idx(array_shape, filter_dim=(3, 3), pad=0, stride=1):\r\n","    n, c, h_in, w_in = array_shape\r\n","    h_f, w_f = filter_dim\r\n","\r\n","    h_out = (h_in + 2 * pad - h_f) // stride + 1\r\n","    w_out = (w_in + 2 * pad - w_f) // stride + 1\r\n","\r\n","    i0 = np.repeat(np.arange(h_f), w_f)\r\n","    i0 = np.tile(i0, c)\r\n","    i1 = stride * np.repeat(np.arange(h_out), w_out)\r\n","    j0 = np.tile(np.arange(w_f), h_f * c)\r\n","    j1 = stride * np.tile(np.arange(w_out), h_out)\r\n","    i = i0.reshape(-1, 1) + i1.reshape(1, -1)\r\n","    j = j0.reshape(-1, 1) + j1.reshape(1, -1)\r\n","    k = np.repeat(np.arange(c), h_f * w_f).reshape(-1, 1)\r\n","    return k, i, j\r\n","\r\n","\r\n","def im2col(array, filter_dim=(3, 3), pad=0, stride=1):\r\n","    _, c, _, _ = array.shape\r\n","    h_f, w_f = filter_dim\r\n","    array_pad = np.pad(\r\n","        array=array,\r\n","        pad_width=((0, 0), (0, 0), (pad, pad), (pad, pad)),\r\n","        mode='constant'\r\n","    )\r\n","    k, i, j = get_im2col_idx(\r\n","        array_shape=array.shape,\r\n","        filter_dim=filter_dim,\r\n","        pad=pad,\r\n","        stride=stride\r\n","    )\r\n","    cols = array_pad[:, k, i, j]\r\n","    return cols.transpose(1, 2, 0).reshape(h_f * w_f * c, -1)\r\n","\r\n","\r\n","def col2im(cols, array_shape, filter_dim=(3, 3), pad=0, stride=1):\r\n","    n, c, h_in, w_in = array_shape\r\n","    h_f, w_f = filter_dim\r\n","    h_pad, w_pad = h_in + 2 * pad, w_in + 2 * pad\r\n","    array_pad = np.zeros((n, c, h_pad, w_pad), dtype=cols.dtype)\r\n","    k, i, j = get_im2col_idx(\r\n","        array_shape=array_shape,\r\n","        filter_dim=filter_dim,\r\n","        pad=pad,\r\n","        stride=stride\r\n","    )\r\n","    cols_reshaped = cols.reshape(c * h_f * w_f, -1, n)\r\n","    cols_reshaped = cols_reshaped.transpose(2, 0, 1)\r\n","    np.add.at(array_pad, (slice(None), k, i, j), cols_reshaped)\r\n","    return array_pad[:, :, pad:pad+h_in, pad:pad+w_in]"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tHnsOYNbg1v-"},"source":["## Layer"]},{"cell_type":"code","metadata":{"id":"ikNXUfMps1Rt","executionInfo":{"status":"ok","timestamp":1608196950949,"user_tz":-180,"elapsed":1134,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class Conv2D:\r\n","    def __init__(self, in_channels, out_channels, kernel_size=(3, 3), stride=1, padding='valid'):\r\n","        self.filter_size = kernel_size\r\n","        self.n_size = (in_channels, out_channels)\r\n","        self.in_channels = in_channels\r\n","        self.out_channels = out_channels\r\n","        self.W = Param(\r\n","            np.random.randn(kernel_size[0], kernel_size[1],\r\n","                            in_channels, out_channels) * 0.1\r\n","        )\r\n","\r\n","        self.B = Param(np.random.randn(out_channels) * 0.1)\r\n","\r\n","        self._padding = padding\r\n","        self._stride = stride\r\n","        self._Z_before = None\r\n","        self._cols = None\r\n","\r\n","    def __str__(self):\r\n","         return \"Conv2D(in_channels={}, out_channels={}, kernel_size=({}, {}), stride={}, padding={})\"\\\r\n","         .format(*self.n_size, *self.n_size, self._stride, self._padding)\r\n","\r\n","    def params(self):\r\n","        return { 'W': self.W.value, 'B': self.B.value }\r\n","    \r\n","    def zero_grad(self):\r\n","        self.W.grad = np.zeros_like(self.W.value)\r\n","        self.B.grad = np.zeros_like(self.B.value)\r\n","\r\n","    def __calculate_output_dims(self, input_dims):\r\n","        n, h_in, w_in, _ = input_dims\r\n","        h_f, w_f, _, n_f = self.W.value.shape\r\n","        if self._padding == 'same':\r\n","            return n, h_in, w_in, n_f\r\n","        elif self._padding == 'valid':\r\n","            h_out = (h_in - h_f) // self._stride + 1\r\n","            w_out = (w_in - w_f) // self._stride + 1\r\n","            return n, h_out, w_out, n_f\r\n","        else:\r\n","            raise Exception(\"Invalid padding!\")\r\n","\r\n","    def __calculate_pad_dims(self):\r\n","        if self._padding == 'same': # ZeroPadding\r\n","            h_f, w_f, _, _ = self.W.value.shape\r\n","            return (h_f - 1) // 2, (w_f - 1) // 2\r\n","        elif self._padding == 'valid':\r\n","            return 0, 0\r\n","        else:\r\n","            raise Exception(\"Invalid padding!\")\r\n","\r\n","    def forward(self, X, training):\r\n","        self._Z_before = np.copy(X)\r\n","        \r\n","        n, h_out, w_out, _ = self.__calculate_output_dims(input_dims=X.shape)\r\n","        h_f, w_f, _, n_f = self.W.value.shape\r\n","        pad = self.__calculate_pad_dims()\r\n","        w = np.transpose(self.W.value, (3, 2, 0, 1))\r\n","\r\n","        self._cols = im2col(\r\n","            array=np.moveaxis(X, -1, 1),\r\n","            filter_dim=(h_f, w_f),\r\n","            pad=pad[0],\r\n","            stride=self._stride\r\n","        )\r\n","\r\n","        result = w.reshape((n_f, -1)).dot(self._cols)\r\n","        output = result.reshape(n_f, h_out, w_out, n)\r\n","\r\n","        return output.transpose(3, 1, 2, 0) + self.B.value\r\n","\r\n","\r\n","    def backward(self, d_out):\r\n","        n, h_out, w_out, _ = self.__calculate_output_dims(\r\n","            input_dims=self._Z_before.shape)\r\n","        h_f, w_f, _, n_f = self.W.value.shape\r\n","        pad = self.__calculate_pad_dims()\r\n","\r\n","        self.B.grad += d_out.sum(axis=(0, 1, 2)) / n\r\n","        d_out_reshaped = d_out.transpose(3, 1, 2, 0).reshape(n_f, -1)\r\n","\r\n","        w = np.transpose(self.W.value, (3, 2, 0, 1))\r\n","        dw = d_out_reshaped.dot(self._cols.T).reshape(w.shape)\r\n","        self.W.grad += np.transpose(dw, (2, 3, 1, 0))\r\n","\r\n","        output_cols = w.reshape(n_f, -1).T.dot(d_out_reshaped)\r\n","\r\n","        output = col2im(\r\n","            cols=output_cols,\r\n","            array_shape=np.moveaxis(self._Z_before, -1, 1).shape,\r\n","            filter_dim=(h_f, w_f),\r\n","            pad=pad[0],\r\n","            stride=self._stride\r\n","        )\r\n","        return np.transpose(output, (0, 2, 3, 1))"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hxzrfId7nj-I"},"source":["# MaxPooling"]},{"cell_type":"code","metadata":{"id":"klkDe27MnlSn","executionInfo":{"status":"ok","timestamp":1608196950950,"user_tz":-180,"elapsed":465,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class MaxPooling:\r\n","    def __init__(self, pool_size, stride):\r\n","        self._pool_size = pool_size\r\n","        self._stride = stride\r\n","        self._Z_before = None\r\n","        self._cache = {}\r\n","\r\n","    def __str__(self):\r\n","         return \"MaxPooling(pool_size=({}, {}), stride={})\"\\\r\n","         .format(*self._pool_size, self._stride)\r\n","\r\n","    def params(self):\r\n","        return {}\r\n","    \r\n","    def zero_grad(self):\r\n","        pass\r\n","\r\n","    def _save_mask(self, X, cords):\r\n","        mask = np.zeros_like(X)\r\n","        n, h, w, c = X.shape\r\n","        X = X.reshape(n, h * w, c)\r\n","        idx = np.argmax(X, axis=1)\r\n","\r\n","        n_idx, c_idx = np.indices((n, c))\r\n","        mask.reshape(n, h * w, c)[n_idx, idx, c_idx] = 1\r\n","        self._cache[cords] = mask\r\n","\r\n","    def forward(self, X, training):\r\n","        self._Z_before = np.copy(X)\r\n","        n, h_in, w_in, c = X.shape\r\n","        h_pool, w_pool = self._pool_size\r\n","        h_out = 1 + (h_in - h_pool) // self._stride\r\n","        w_out = 1 + (w_in - w_pool) // self._stride\r\n","        output = np.zeros((n, h_out, w_out, c))\r\n","\r\n","        for i in range(h_out):\r\n","            for j in range(w_out):\r\n","                h_start = i * self._stride\r\n","                h_end = h_start + h_pool\r\n","                w_start = j * self._stride\r\n","                w_end = w_start + w_pool\r\n","                X_slice = X[:, h_start:h_end, w_start:w_end, :]\r\n","                self._save_mask(X_slice, (i, j))\r\n","                output[:, i, j, :] = np.max(X_slice, axis=(1, 2))\r\n","        return output\r\n","\r\n","    def backward(self, d_out):\r\n","        output = np.zeros_like(self._Z_before)\r\n","        _, h_out, w_out, _ = d_out.shape\r\n","        h_pool, w_pool = self._pool_size\r\n","\r\n","        for i in range(h_out):\r\n","            for j in range(w_out):\r\n","                h_start = i * self._stride\r\n","                h_end = h_start + h_pool\r\n","                w_start = j * self._stride\r\n","                w_end = w_start + w_pool\r\n","                output[:, h_start:h_end, w_start:w_end, :] += \\\r\n","                    d_out[:, i:i + 1, j:j + 1, :] * self._cache[(i, j)]\r\n","        return output\r\n","\r\n","    def params(self):\r\n","        return {}"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3Kvl6RcYgWeO"},"source":["# Flattener"]},{"cell_type":"code","metadata":{"id":"6OEKfNYHgWl_","executionInfo":{"status":"ok","timestamp":1608196952318,"user_tz":-180,"elapsed":864,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class Flattener:\r\n","    def __init__(self):\r\n","        self.X_shape = None\r\n","\r\n","    def __str__(self):\r\n","         return \"Flattener()\"\r\n","\r\n","    def params(self):\r\n","        return {}\r\n","    \r\n","    def zero_grad(self):\r\n","        pass\r\n","\r\n","    def forward(self, X, training):\r\n","        batch_size, height, width, channels = X.shape\r\n","        self.X_shape = X.shape\r\n","        return np.ravel(X).reshape(X.shape[0], -1)\r\n","\r\n","    def backward(self, d_out):\r\n","        return d_out.reshape(self.X_shape)\r\n","\r\n","    def params(self):\r\n","        return {}"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XX4bEcFcgZS6"},"source":["# Dropout"]},{"cell_type":"code","metadata":{"id":"WgQI4fkRgZY6","executionInfo":{"status":"ok","timestamp":1608196953011,"user_tz":-180,"elapsed":768,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class Dropout:\r\n","    def __init__(self, keep_prob):\r\n","        self._keep_prob = keep_prob\r\n","        self._mask = None\r\n","    \r\n","    def __str__(self):\r\n","         return \"Dropout(keep_prob={})\".format(self._keep_prob)\r\n","\r\n","    def params(self):\r\n","        return {}\r\n","    \r\n","    def zero_grad(self):\r\n","        pass\r\n","\r\n","    def forward(self, X, training):\r\n","        if training:\r\n","            self._mask = (np.random.rand(*X.shape) < self._keep_prob)\r\n","            return self._apply_mask(X, self._mask)\r\n","        else:\r\n","            return X\r\n","\r\n","    def backward(self, d_out):\r\n","        return self._apply_mask(d_out, self._mask)\r\n","\r\n","    def _apply_mask(self, array, mask):\r\n","        array *= mask\r\n","        array /= self._keep_prob\r\n","        return array"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IsXzkFymgbFO"},"source":["# Net"]},{"cell_type":"code","metadata":{"id":"_LVcDPLagbKm","executionInfo":{"status":"ok","timestamp":1608197082624,"user_tz":-180,"elapsed":766,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class NeuralNetwork:\r\n","    def __init__(self, layers):\r\n","        self.__layers = layers\r\n","        self.__optimizer = None\r\n","    \r\n","    def __getitem__(self, id):\r\n","        return self.__layers[id]\r\n","\r\n","    def __str__(self):\r\n","        str_net = \"NeuralNetwork {\\n\"\r\n","        for l in self.__layers:\r\n","            str_net += \"\\t{}\\n\".format(str(l))\r\n","        str_net += \"}\"\r\n","        return str_net\r\n","\r\n","    def save_weights(self, name='weights'):\r\n","        f = open(r'{}.pickle'.format(name), 'wb')\r\n","        obj = self.params()\r\n","        pickle.dump(obj, f)\r\n","        print('The model is saved to file - {}.pickle!'.format(name))\r\n","        f.close()\r\n","    \r\n","    def load_weights(self, weights=None, path='weights.pickle'):\r\n","        if weights is None:\r\n","            f = open(path, 'rb')\r\n","            obj = pickle.load(f)\r\n","            f.close()\r\n","        else:\r\n","            obj = weights\r\n","        i = 0\r\n","        for l in self.__layers:\r\n","            if not hasattr(l, 'W'):\r\n","                continue\r\n","            l.W.value = obj[i]['weight']\r\n","            l.B.value = obj[i]['bias']\r\n","            i += 1\r\n","\r\n","    def params(self):\r\n","        return [l.params() for l in self.__layers if hasattr(l, 'W')]\r\n","    \r\n","    def initNorm(self, sigma):\r\n","        for l in self.__layers:\r\n","            if hasattr(l, 'W'):\r\n","                l.W.value = np.random.randn(*l.W.value.shape) * sigma\r\n","                l.B.value = np.random.randn(*l.B.value.shape) * sigma\r\n","    \r\n","    def initHe(self):\r\n","        for l in self.__layers:\r\n","            if hasattr(l, 'W'):\r\n","                l.W.value = np.random.randn(*l.W.value.shape) * np.sqrt(2 / l.n_size[0])\r\n","                l.B.value = np.random.randn(*l.B.value.shape) * np.sqrt(2 / l.n_size[0])\r\n","    \r\n","    def initXavier(self):\r\n","        for l in self.__layers:\r\n","            if hasattr(l, 'W'):\r\n","                l.W.value = np.random.randn(*l.W.value.shape) * np.sqrt(2 / (l.n_size[0] + l.n_size[1]))\r\n","                l.B.value = np.random.randn(*l.B.value.shape) * np.sqrt(2 / (l.n_size[0] + l.n_size[1]))\r\n","    \r\n","    def zero_grad(self):\r\n","        for l in self.__layers:\r\n","            l.zero_grad()\r\n","    \r\n","    def set_optimizer(self, optimizer):\r\n","        self.__optimizer = optimizer\r\n","    \r\n","    def forward(self, x_set, training):\r\n","        x_ = np.copy(x_set)\r\n","        for l in self.__layers:\r\n","            x_ = l.forward(x_, training)\r\n","        return x_\r\n","    \r\n","    def backward(self, net_out, t_set):\r\n","        d_out = net_out.copy()\r\n","        t_mask = np.zeros(d_out.shape)\r\n","        t_mask[np.arange(len(t_set)), t_set.reshape(1, -1)] = 1\r\n","        d_out -= t_mask\r\n","        for l in reversed(self.__layers):\r\n","            d_out = l.backward(d_out)\r\n","    \r\n","    def step(self):\r\n","        self.__optimizer.update_weight(self.__layers)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pRWO33X4KWYG"},"source":["# Optimizers"]},{"cell_type":"code","metadata":{"id":"6CRfnM7pKYO-","executionInfo":{"status":"ok","timestamp":1608197770796,"user_tz":-180,"elapsed":654,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class Adam:\r\n","    def __init__(self, lr, reg=0, beta1=0.9, beta2=0.999, eps=1e-8):\r\n","        self._lr = lr\r\n","        self._reg = reg\r\n","        self._beta1 = beta1\r\n","        self._beta2 = beta2\r\n","        self._cache_v = {}\r\n","        self._cache_s = {}\r\n","        self._eps = eps\r\n","    \r\n","    def _init_cache(self, layers):\r\n","        for idx, l in enumerate(layers):\r\n","            if hasattr(l, 'W'):\r\n","                dw, db = l.W.grad, l.B.grad\r\n","                if dw is None or db is None:\r\n","                    continue\r\n","\r\n","                dw_key, db_key = Adam._get_keys(idx)\r\n","\r\n","                self._cache_v[dw_key] = np.zeros_like(dw)\r\n","                self._cache_v[db_key] = np.zeros_like(db)\r\n","                self._cache_s[dw_key] = np.zeros_like(dw)\r\n","                self._cache_s[db_key] = np.zeros_like(db)\r\n","        \r\n","    @staticmethod\r\n","    def _get_keys(idx):\r\n","        return f\"dw{idx}\", f\"db{idx}\"\r\n","\r\n","    def update_weight(self, layers):\r\n","        if len(self._cache_s) == 0 or len(self._cache_v) == 0:\r\n","            self._init_cache(layers)\r\n","\r\n","        if self._reg:\r\n","            for l in reversed(layers):\r\n","                if hasattr(l, 'W'):\r\n","                    l.W.grad += reg * 2 * l.W.value\r\n","\r\n","        for idx, l in enumerate(layers):\r\n","            if hasattr(l, 'W'):\r\n","                dw_key, db_key = Adam._get_keys(idx)\r\n","\r\n","                self._cache_v[dw_key] = self._beta1 * self._cache_v[dw_key] + \\\r\n","                (1 - self._beta1) * l.W.grad\r\n","                self._cache_v[db_key] = self._beta1 * self._cache_v[db_key] + \\\r\n","                    (1 - self._beta1) * l.B.grad\r\n","\r\n","                self._cache_s[dw_key] = self._beta2 * self._cache_s[dw_key] + \\\r\n","                    (1 - self._beta2) * np.square(l.W.grad)\r\n","                self._cache_s[db_key] = self._beta2 * self._cache_s[db_key] + \\\r\n","                    (1 - self._beta2) * np.square(l.B.grad)\r\n","\r\n","                dw = self._cache_v[dw_key] / (np.sqrt(self._cache_s[dw_key]) + self._eps)\r\n","                db = self._cache_v[db_key] / (np.sqrt(self._cache_s[db_key]) + self._eps)\r\n","\r\n","                l.W.value -= self._lr * dw\r\n","                l.B.value -= self._lr * db\r\n","\r\n","class SGD:\r\n","    def __init__(self, lr, reg=0, momentum=0.9):\r\n","        self._lr = lr\r\n","        self._reg = reg\r\n","        self._momentum = momentum\r\n","        self._cache_vx = {}\r\n","    \r\n","    def _init_cache(self, layers):\r\n","        for idx, l in enumerate(layers):\r\n","            if hasattr(l, 'W'):\r\n","                dw, db = l.W.grad, l.B.grad\r\n","                if dw is None or db is None:\r\n","                    continue\r\n","\r\n","                dw_key, db_key = SGD._get_keys(idx)\r\n","\r\n","                self._cache_vx[dw_key] = np.zeros_like(dw)\r\n","                self._cache_vx[db_key] = np.zeros_like(db)\r\n","\r\n","    @staticmethod\r\n","    def _get_keys(idx):\r\n","        return f\"dw{idx}\", f\"db{idx}\"\r\n","    \r\n","    def update_weight(self, layers):\r\n","        if self._reg:\r\n","            for l in reversed(layers):\r\n","                if hasattr(l, 'W'):\r\n","                    l.W.grad += reg * 2 * l.W.value\r\n","\r\n","        for idx, l in enumerate(layers):\r\n","            if hasattr(l, 'W'): \r\n","                dw_key, db_key = SGD._get_keys(idx)\r\n","\r\n","                self._cache_vx[dw_key] = self._momentum * self._cache_vx[dw_key] + l.W.grad\r\n","                self._cache_vx[db_key] = self._momentum * self._cache_vx[db_key] + l.B.grad\r\n","\r\n","                l.W.value -= self._lr * self._cache_vx[dw_key]\r\n","                l.B.value -= self._lr * self._cache_vx[db_key]\r\n","\r\n","class RMSProp:\r\n","    def __init__(self, lr, reg=0, momentum=0.9):\r\n","        self._lr = lr\r\n","        self._reg = reg\r\n","        self._cache = {}\r\n","        self._beta = beta\r\n","        self._eps = eps\r\n","    \r\n","    def _init_cache(self, layers: List[Layer]) -> None:\r\n","        for idx, l in enumerate(layers):\r\n","            if hasattr(l, 'W'):\r\n","                dw, db = l.W.grad, l.B.grad\r\n","                if dw is None or db is None:\r\n","                    continue\r\n","\r\n","                dw_key, db_key = RMSProp._get_keys(idx)\r\n","\r\n","                self._cache[dw_key] = np.zeros_like(dw)\r\n","                self._cache[db_key] = np.zeros_like(db)\r\n","    \r\n","    @staticmethod\r\n","    def _get_keys(idx):\r\n","        return f\"dw{idx}\", f\"db{idx}\"\r\n","    \r\n","    def update_weight(self, layers):\r\n","        if len(self._cache_s) == 0 or len(self._cache_v) == 0:\r\n","            self._init_cache(layers)\r\n","\r\n","        if self._reg:\r\n","            for l in reversed(layers):\r\n","                if hasattr(l, 'W'):\r\n","                    l.W.grad += reg * 2 * l.W.value\r\n","\r\n","        for idx, l in enumerate(layers):\r\n","            if hasattr(l, 'W'):\r\n","                dw_key, db_key = RMSProp._get_keys(idx)\r\n","\r\n","                self._cache[dw_key] = self._beta * self._cache[dw_key] + \\\r\n","                (1 - self._beta) * np.square(l.W.grad)\r\n","                self._cache[db_key] = self._beta * self._cache[db_key] + \\\r\n","                    (1 - self._beta) * np.square(l.B.grad)\r\n","\r\n","                dw = l.W.grad / (np.sqrt(self._cache[dw_key]) + self._eps)\r\n","                db = l.B.grad / (np.sqrt(self._cache[db_key]) + self._eps)\r\n","\r\n","                l.W.value -= self._lr * dw\r\n","                l.B.value -= self._lr * db"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LgdonI1VsttS"},"source":["# Criterion"]},{"cell_type":"code","metadata":{"id":"IcAdEFY8sQeb","executionInfo":{"status":"ok","timestamp":1608197772779,"user_tz":-180,"elapsed":1012,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["class Criterion:\r\n","    def __init__(self, name, reduction=True):\r\n","        if name == 'CrossEntropy':\r\n","            self.__loss_func = self.__CrossEntropyLoss\r\n","        elif name == 'MSELoss':\r\n","            self.__loss_func = self.__MSELoss\r\n","        elif name == 'L1Loss':\r\n","            self.__loss_func = self.__L1Loss\r\n","        elif name == 'BCELoss':\r\n","            self.__loss_func = self.__BCELoss\r\n","        else:\r\n","            raise Exception(\"Invalid criteria!\")\r\n","        if reduction:\r\n","            self.__reduc = np.mean\r\n","        else:\r\n","            self.__reduc = np.sum\r\n","    \r\n","    def __CrossEntropyLoss(self, pred_set, t_set):\r\n","        return -self.__reduc(np.log(pred_set[np.arange(len(t_set)), t_set.reshape(1, -1)]))\r\n","    \r\n","    def __MSELoss(self, pred_set, t_set):\r\n","        return self.__reduc((pred_set - t_set) ** 2)\r\n","    \r\n","    def __L1Loss(self, pred_set, t_set):\r\n","        return self.__reduc(np.linalg.norm(pred_set - t_set, axis=1))\r\n","\r\n","    def __BCELoss(self, pred_set, t_set):\r\n","        return -self.__reduc(np.log(pred_set) * t_set + np.log(1 - pred_set) * (1 - t_set))\r\n","    \r\n","    def loss(self, pred_set, t_set):\r\n","        return self.__loss_func(pred_set, t_set)"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RA2-58khkPfH"},"source":["# Metrics"]},{"cell_type":"code","metadata":{"id":"cy8wvN4bsQgF","executionInfo":{"status":"ok","timestamp":1608197775457,"user_tz":-180,"elapsed":681,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["def Accuracy(pred_set, t_set):\r\n","    return np.sum(pred_set.argmax(axis=1) == t_set) / t_set.shape[0]\r\n","\r\n","def batchAccuracy(model, Loader):\r\n","    Acc, Num = 0, 0\r\n","    for batch in Loader:\r\n","        img = batch['imgs'] / 255\r\n","        targets = batch['targets']\r\n","\r\n","        output = model.forward(img, False)\r\n","        Acc += np.sum(output.argmax(axis=1) == targets)\r\n","        Num += img.shape[0]\r\n","    return Acc / Num\r\n","\r\n","def ConfusionMatrix(pred_set, t_set, norm=False):\r\n","    pred_labels = pred_set.argmax(axis=1)\r\n","    cm = np.zeros((pred_set.shape[1], pred_set.shape[1]))\r\n","    for i in range(len(t_set)):\r\n","        cm[int(t_set[i])][int(pred_labels[i])] += 1"],"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gw7HVjqvkTOV"},"source":["# Training"]},{"cell_type":"markdown","metadata":{"id":"TlLmu8-ApmKt"},"source":["Load CIFAR-10"]},{"cell_type":"code","metadata":{"id":"4t5Kau6MvVYK","executionInfo":{"status":"ok","timestamp":1608197899762,"user_tz":-180,"elapsed":3179,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["!tar -xzf cifar-10-python.tar.gz"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0GEx7ykz3EY","executionInfo":{"status":"ok","timestamp":1608199062918,"user_tz":-180,"elapsed":687,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["path_batches = 'cifar-10-batches-py/'\r\n","files = {'train': ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4'],\r\n","         'valid': ['data_batch_5'],\r\n","         'test': ['test_batch']}\r\n","\r\n","TrainLoader = getLoader(path=path_batches, samples=files['train'], batch_size=25, shuff=True)\r\n","ValidLoader = getLoader(path=path_batches, samples=files['valid'], batch_size=25)\r\n","TestLoader = getLoader(path=path_batches, samples=files['test'], batch_size=25)"],"execution_count":59,"outputs":[]},{"cell_type":"code","metadata":{"id":"sdRibhYikTTx","executionInfo":{"status":"ok","timestamp":1608199063330,"user_tz":-180,"elapsed":815,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["layers = [\r\n","    Conv2D(3, 32, kernel_size=(5, 5), stride=1, padding='same'),\r\n","    ReLU(),\r\n","    MaxPooling(pool_size=(2, 2), stride=2),\r\n","    Conv2D(32, 32, kernel_size=(5, 5), stride=1, padding='same'),\r\n","    ReLU(),\r\n","    MaxPooling(pool_size=(2, 2), stride=2),\r\n","    Conv2D(32, 64, kernel_size=(5, 5), stride=1, padding='same'),\r\n","    ReLU(),\r\n","    MaxPooling(pool_size=(2, 2), stride=2),\r\n","    Flattener(),\r\n","    FullyConnected(1024, 10),\r\n","    Softmax()\r\n","]\r\n","\r\n","model = NeuralNetwork(layers)\r\n","model.set_optimizer(Adam(0.001))"],"execution_count":60,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2p4HAFpHpCV","executionInfo":{"status":"ok","timestamp":1608199063597,"user_tz":-180,"elapsed":588,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}}},"source":["from IPython import display\r\n","\r\n","def train(model, TrainLoader, ValidLoader, epochs, criterion):\r\n","    train_loss = []\r\n","    val_loss = []\r\n","    for epoch in range(epochs):\r\n","        display.clear_output(wait=True)\r\n","\r\n","        train_loss_batch = []\r\n","        val_loss_batch = []\r\n","        # Train\r\n","        for batch in TrainLoader:\r\n","            img = batch['imgs'] / 255\r\n","            targets = batch['targets']\r\n","            \r\n","            model.zero_grad()\r\n","            output = model.forward(img, training=True)\r\n","            model.backward(output, targets)\r\n","            model.step()\r\n","\r\n","            output = model.forward(img, training=False)\r\n","            train_loss_batch.append(criterion.loss(output, targets))\r\n","        \r\n","        # Validation\r\n","        for batch in ValidLoader:\r\n","            img = batch['imgs'] / 255\r\n","            targets = batch['targets']\r\n","            \r\n","            output = model.forward(img, training=False)\r\n","            val_loss_batch.append(criterion.loss(output, targets))\r\n","        \r\n","        train_loss.append(np.nanmean(train_loss_batch))\r\n","        val_loss.append(np.nanmean(val_loss_batch))\r\n","        \r\n","        plt.figure('Training')\r\n","        plt.plot(train_loss, label='Train loss')\r\n","        plt.plot(val_loss, label='Valid loss')\r\n","        plt.legend()\r\n","        plt.show()"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"WTluD-cPqPjb"},"source":["criterion = Criterion('CrossEntropy')\r\n","train(model, TrainLoader, ValidLoader, 50, criterion)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyuQr9JGOltB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608128986498,"user_tz":-180,"elapsed":52944,"user":{"displayName":"Vladislav Viryasov","photoUrl":"","userId":"01528974730323659583"}},"outputId":"558191f4-b7ca-4d7b-8357-0f27e1adfd35"},"source":["print('Test Accuracy - {}'.format(batchAccuracy(model, TestLoader)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test Accuracy - 0.575\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZuD6gmnSmTjR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"po3fYUHqmTmJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GXHzAvRrmTps"},"source":[""],"execution_count":null,"outputs":[]}]}